{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mxfXul2RxlRB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 05:29:54.772590: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 05:29:55.497190: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy.__version__:   1.11.1\n",
      "tensorflow_privacy.__version__:   0.8.10\n"
     ]
    }
   ],
   "source": [
    "# general imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "# tensorflow imports\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, MaxPooling2D,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# tensorflow-privacy\n",
    "import tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.membership_inference_attack as mia\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import AttackInputData\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import SlicingSpec\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import AttackType\n",
    "\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from numpy.random import choice, seed\n",
    "from numpy import ndarray, concatenate, stack, array, round, zeros, arange\n",
    "import numpy as np\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import pickle\n",
    "\n",
    "from os import mkdir, path\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from warnings import simplefilter\n",
    "simplefilter('ignore', category=FutureWarning)\n",
    "simplefilter('ignore', category=DeprecationWarning)\n",
    "\n",
    "import scipy\n",
    "print(\"scipy.__version__:  \", scipy.__version__)\n",
    "\n",
    "import tensorflow_privacy.privacy\n",
    "print(\"tensorflow_privacy.__version__:  \", tensorflow_privacy.__version__)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the TEST (non-Member) set (i.e., test set for the classifier model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open(f'/home/privacy-master/DataShare/Adult_test5k_capped',\"rb\")\n",
    "dfTest=pickle.load(filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "0    3761\n",
       "1    1239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest [\"income\"] = np.where(dfTest['income'] == '<=50K' , 0, 1)\n",
    "dfTest[\"income\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read the TRAIN sanitized sets (Member) (i.e., train dataset for the classifier model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filehandler = open(f'/home/privacy-master/DataShare/Adult_k5_100.pkl',\"rb\")\n",
    "dataFiles=pickle.load(filehandler)\n",
    "filehandler.close()\n",
    "len(dataFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataFiles)):\n",
    "    dataFiles[i][\"income\"] = np.where(dataFiles[i]['income'] == '<=50K' , 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = dfTest['income']\n",
    "X_test = dfTest.drop(['income'], axis=1)\n",
    "\n",
    "categorical = [col for col in X_test.columns if X_test[col].dtypes == 'O']\n",
    "#print(categorical)\n",
    "numerical = [col for col in X_test.columns if X_test[col].dtypes != 'O']\n",
    "#print(numerical)\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'gender', 'native_country'])\n",
    "#TexasRawDF=TexasRawDF.drop(['RISK_MORTALITY'], axis=1)\n",
    "encoder.fit(dfTest.drop([\"income\"], axis=1))\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Classifier Begin ###########################################\n",
    "k_ = [\"5\"]\n",
    "utility_score={}\n",
    "MIA_score={}\n",
    "for k in k_:#k = 10, 20, 35, 50\n",
    "    utility_score[k]=[]\n",
    "    MIA_score[k]=[]\n",
    "    \n",
    "    utility_score[k]=[]\n",
    "    MIA_score[k]=[]\n",
    "\n",
    "    \n",
    "    for set_no in range(100):\n",
    "\n",
    "        df=dataFiles[set_no]\n",
    "        if (len(df)==0):\n",
    "            continue\n",
    "        count = df['income'].value_counts()\n",
    "\n",
    "\n",
    "        y_train = df['income']\n",
    "        X_train = df.drop(['income'], axis=1)\n",
    "        X_train = encoder.transform(X_train)\n",
    "\n",
    "        cols = X_train.columns\n",
    "        scaler = RobustScaler()\n",
    "\n",
    "        X_test = scaler.fit_transform(X_test)\n",
    "        X_train = scaler.transform(X_train)\n",
    "\n",
    "        X_train = pd.DataFrame(X_train, columns=[cols])\n",
    "        X_test = pd.DataFrame(X_test, columns=[cols])\n",
    "\n",
    "        # instantiate the classifier with n_estimators = 100\n",
    "        rfc_100 = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "        # fit the model to the training set\n",
    "        rfc_100.fit(X_train, y_train)            \n",
    "\n",
    "        # Predict on the test set results\n",
    "        y_pred_100 = rfc_100.predict(X_test)\n",
    "\n",
    "        # Check accuracy score \n",
    "        #print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))\n",
    "        utility_score[k].append(accuracy_score(y_test, y_pred_100))\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        INx_train_pred1 = rfc_100.predict_proba(X_train)\n",
    "        OUTx_test_pred1 = rfc_100.predict_proba(X_test)\n",
    "\n",
    "        \n",
    "        INx_train_pred = np.zeros((len(X_train), 2))\n",
    "        INx_train_pred[0:len(X_train), 0:INx_train_pred1.shape[1]]=INx_train_pred1\n",
    "        OUTx_test_pred = np.zeros((len(X_test), 2))\n",
    "        OUTx_test_pred[0:len(X_test), 0:OUTx_test_pred1.shape[1]] = OUTx_test_pred1\n",
    "\n",
    "        probs_train = INx_train_pred\n",
    "        probs_test = OUTx_test_pred\n",
    "        #labels_train = y_train\n",
    "        labels_train = np.zeros((len(INx_train_pred)))\n",
    "        labels_train[0:len(INx_train_pred)] = y_train\n",
    "        labels_train = labels_train.astype(int)\n",
    "        #labels_test = y_test\n",
    "        labels_test = np.zeros((len(OUTx_test_pred)))\n",
    "        labels_test[0:len(OUTx_test_pred)] = y_test\n",
    "        labels_test=labels_test.astype(int)\n",
    "\n",
    "        # define what variables our attacker should have access to\n",
    "        attack_input = AttackInputData(\n",
    "          probs_train = probs_train,\n",
    "          probs_test = probs_test,\n",
    "          #loss_train = loss_train,\n",
    "          #loss_test = loss_test,\n",
    "          labels_train = labels_train,\n",
    "          labels_test = labels_test,\n",
    "          multilabel_data = False#True\n",
    "        )\n",
    "\n",
    "        # how should the data be sliced\n",
    "        slicing_spec = SlicingSpec(\n",
    "            entire_dataset = True,\n",
    "            by_class = False,#not supported for multilabel\n",
    "            by_percentiles = False,\n",
    "            by_classification_correctness = False)#not supported for multilabel\n",
    "\n",
    "        # define the type of attacker model that we want to use\n",
    "        attack_types = [\n",
    "            #AttackType.THRESHOLD_ATTACK,\n",
    "            AttackType.RANDOM_FOREST#LOGISTIC_REGRESSION\n",
    "        ]\n",
    "\n",
    "        # run the attack\n",
    "        attacks_result = mia.run_attacks(attack_input=attack_input,\n",
    "                                         slicing_spec=slicing_spec,\n",
    "                                         balance_attacker_training = False,\n",
    "                                         attack_types=attack_types)\n",
    "\n",
    "        #print(attacks_result.summary(by_slices=True))                        \n",
    "        MIA_score[k].append(attacks_result.summary(by_slices=True))\n",
    "        #print(attacks_result.summary(by_slices=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: \n",
      "epoch = 5\n",
      "0.76\n",
      "100\n",
      "Average: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Accuracy: \")\n",
    "for k in k_:\n",
    "    print(f\"epoch = {k}\")\n",
    "    all_id_sum=0\n",
    "    \n",
    "    all_id_sum+= ((sum(utility_score[k]))/len(utility_score[k]))\n",
    "    print(\"%.2f\"% ((sum(utility_score[k]))/len(utility_score[k])))\n",
    "    print(len(utility_score[k]))\n",
    "    print(\"Average: %.2f\"% (all_id_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIA result: \n",
      "k = 5\n",
      "Average AUC: 0.84 \tADV: 0.54 \tPPV: 0.99\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(\"MIA result: \")\n",
    "for k in k_:\n",
    "    print(f\"k = {k}\")\n",
    "    all_id_AUCsum, all_id_ADVsum, all_id_PPVsum = 0, 0, 0\n",
    "    \n",
    "        \n",
    "    temp_AUCsum, temp_ADVsum, temp_PPVsum = 0, 0, 0\n",
    "    for str1 in MIA_score[k]:       \n",
    "        result = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", str1)\n",
    "        temp_AUCsum += float(result[2])\n",
    "        temp_ADVsum += float(result[5])\n",
    "        temp_PPVsum += float(result[8])\n",
    "    temp_AUCsum /= len(MIA_score[k])#100\n",
    "    temp_ADVsum /= len(MIA_score[k])#100\n",
    "    temp_PPVsum /= len(MIA_score[k])#100\n",
    "    print(\"Average AUC: %.2f \\tADV: %.2f \\tPPV: %.2f\"% (temp_AUCsum, temp_ADVsum, temp_PPVsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "tfMIA",
   "language": "python",
   "name": "tfmia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
